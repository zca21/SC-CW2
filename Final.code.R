#Setting up enviroment
setwd("~/Desktop/Statistical Computing/CW/SC-CW2")

######################### Question 1 ###############################

### Part a ###

#Creating plot to help explain choosing value of lambda with highest acceptance rate

#Note assume a=2, b=3 and s=1.25 for all functions creating pdfs below

#Function of pdf of proposal density with lambda=1
gx.1 <- function(x){
  gx <- 0.5*exp(-abs(x-3))
  return(gx)
}

#Function of pdf of proposal density with lambda=0.5
gx.2 <- function(x){
  gx <- 0.25*exp(-0.5*abs(x-3))
  return(gx)
}

#Creating function to create actual pdf of target distribution 
target.dist<- function(x){
  pi <-NULL
  for (i in 1:length(x)){
    if (x[i]>1.25){
      pi[i] <- (2*1.25^(2))/(2*x[i]^(3))
    } else if (x[i] >= -1.75){
      pi[i] <- 1/6
    }else{
      pi[i] <- 0
    }
  }
  return(pi)
}

#Creating plot
x<- seq(from=-4, to=10, by=0.01)

plot(x=x,y=target.dist(x),
     type="l",
     ylab = "density",
     main="Plot 1: Comparing target and proposal pdf's",
     sub="Note: used a=2,b=3,s=1.25 with the green line seperating the regions of the graph")
curve(gx.1(x),add=T,col="red")
curve(gx.2,add=T,col="blue")
abline(v=-1.75,lty=2,col="green")
abline(v=1.25,lty=2,col="green")
text(x=-3,y=0.4,labels="Region 1")
text(x=0,y=0.4,labels="Region 2")
text(x=6,y=0.4,labels="Region 3")
legend("topright", lty = c(1,1,1), cex = 0.6, col = c("black","red","blue"),
       legend = c("Target distribution pdf","g(x) pdf with lambda=1","g(x) pdf with lambda=0.5"))

### Part c ###

q1.ar <- function(n,a,b,s,lambda,M){
  #Creating vector to store values from target distribution
  X <- NULL
  for (i in 1:n){
    repeat{
      #Drawing samples x from the propsal distibution using inverse transformation technique
      u <- runif(1)
      if (u<0.5){
        x <- b+log(2*u)/lambda
      }else {
        x <- b-log(2-2*u)/lambda
      }
      #Performing Accept - Reject
      y <- runif(1)
      #Checking if in region 3
      if (s < x){
        if(y <= (a*s^a)/(2*x^(a+1))/(M*lambda*exp(-lambda*abs(x-b))/2)){
          X[i]<-x
          break
        }
        #Checking if in region 2
      } else if(s-b<x){
        if(y <= 1/(2*b)/(M*lambda*exp(-lambda*abs(x-b))/2)){
          X[i]<-x
          break
        }
      }
    }
  }
  return(X)
}

### Part d ###

set.seed(2022)
#Performing AR sampling using function created in part c and with specified values of parameters
ar.sample <- q1.ar(5000,2,3,1.25,0.5,M=3.2*exp(0.875))

#Using function created in part a to plot actual pdf of target distribution

#Creating plot of sampled distribution from AR sampling and actual curve of real pdf of target distribution 
hist(ar.sample,nclass=100,prob = T,
     xlab = "Values generated by AR sampling",
     main = "Simulated and actual pdf of target distribution");
curve(target.dist(x),from=-4,to=20,n=1000,add=T, lwd= 1, lty= 1,col="red");
legend("topright", lty = c(1), cex = 0.6, col = c("red"),
       legend = c("Actual pdf"))

### Part e ###

#Using the plain Monte Carlo estimator of I (I_{n})

#Function to calculate the kth root of kth moment using plain Monte Carlo estimator
k.root.k.moment <- function(sample,n,k){
  output <- (1/n*sum(sample^k))^(1/k)
  return(output)
}

#using k=2
round(k.root.k.moment(ar.sample,5000,2),3)
#2nd root of 2nd moment is 2.204 (3 d.p.)

#using k=3
round(k.root.k.moment(ar.sample,5000,3),3)
#3rd root of 3rd moment is 3.350 (3 d.p.)


########################################## Question 4 #################################################

### Part a ###

linRegMixEstep <- function(piCur,aCur,bCur,sCur,x,Y){
  # Initalisiong matrix to store E-Step values called prob
  prob <- matrix(data=NA,nrow = length(x),ncol = length(piCur))
  for (i in 1:length(x)){
    for (j in 1:length(piCur)){
      #Calculating probability in cell (i,j) of matrix using equation 15, 16 and 17 in the the coursework sheet
      prob[i,j] <- piCur[j]*dnorm(Y[i],mean=aCur[j]+bCur[j]*x[i],sd=sCur[j])/sum(piCur*dnorm(Y[i],mean=aCur+bCur*x[i],sd=sCur))
    }
  }
  return(prob)
}

### Part b ###

### (i)

calcNewCoefs <- function(W,x,Y){
  #Setting up matrix to store values of new coefficients in
  new.coef <- matrix(data=NA,ncol = 2,nrow=dim(W)[2])
  #Creating design matrix
  X <- matrix(c(rep(1,length(x)),x),ncol=2)
  
  #Calculating a^{new) and b^{new}
  for (k in 1:dim(W)[2]){
    new.coef[k,] <- solve(t(X)%*%diag(W[,k])%*%X)%*%t(X)%*%diag(W[,k])%*%Y
  }
  return(t(new.coef))
}

### (ii)

calcNewSd <- function(W,x,Y,a,b){
  new.sd <- NULL
  #calculating new sd
  for (k in 1:dim(W)[2]){
    new.sd[k] <- sqrt(sum(W[,k]*(Y-a[k]-b[k]*x)^2)/sum(W[,k]))
  }
  return(new.sd)
}

### (iii)

linRegMixMstep <- function(W,x,Y){
  #calculating new coefficents for a and b
  new.coef <- calcNewCoefs(W,x,Y)
  
  #calculating new sd
  new.sd <- calcNewSd(W,x,Y,new.coef[1,],new.coef[2,]) 
  
  #Calculating new pi
  new.pi <- NULL
  for (k in 1:dim(W)[2]){
    new.pi[k] <- sum(W[,k])/dim(W)[1]
  }
  return(list(new.pi,new.coef[1,],new.coef[2,],new.sd))
}

### Part c ###
linRegMixCalcLogLik <- function(x,Y,piCur,piNew,aCur,aNew,bCur,bNew,sCur,sNew){
  #calculating conditional probabilities for current and new values of theta
  W.cur <- linRegMixEstep(piCur,aCur,bCur,sCur,x,Y)
  W.new <- linRegMixEstep(piNew,aNew,bNew,sNew,x,Y)
  #Creating object to store values of log-likelihood for each observation i of Y 
  Q.cur <- Q.new <-NULL

  for (i in 1:length(Y)){
    #calculating log likelihood for each observed value of Y
    Q.cur[i] <- sum(W.cur[i,]*log(piCur))+sum(W.cur[i,]*log(dnorm(Y[i],mean = aCur+bCur*x[i],sd=sCur)))
    Q.new[i] <- sum(W.new[i,]*log(piNew))+sum(W.new[i,]*log(dnorm(Y[i],mean = aNew+bNew*x[i],sd=sNew)))
  }
  #Summing over all observations as is in the formula in lecture slides
  Q.cur <- sum(Q.cur)
  Q.new <- sum(Q.new)
  return(c(Q.cur,Q.new))
}

### part d ###

linRegMixEM <- function(piInit,aInit,bInit,sInit,x,Y,convergeEps){
  #Initializing the algorithm
  piCur <- piInit
  aCur <- aInit
  bCur <- bInit
  sCur <- sInit
  
  conv.critera <- 0
  while(conv.critera==0){
    #E-step
    W <- linRegMixEstep(piCur,aCur,bCur,sCur,x,Y)
    #Calculating new values for parameters
    theta.new <- linRegMixMstep(W,x,Y)
    #Calculating log-likelihood for current and new values of parameters
    theta.loglik <- linRegMixCalcLogLik(x,Y,piCur,theta.new[[1]],aCur,theta.new[[2]],bCur,theta.new[[3]],sCur,theta.new[[4]])
    #checking convergence criteria
    if(abs(theta.loglik[2]-theta.loglik[1])<convergeEps){
      conv.critera=1
    }
    #Updating current values of parameters to those that met the convergence criteria
    piCur <- theta.new[[1]]
    aCur <- theta.new[[2]]
    bCur <- theta.new[[3]]
    sCur <- theta.new[[4]]
  }
  return(theta.new)
}

### Part e ###

# Importing in data
q4.data <- read.csv("q4MixLinReg.csv",header=T)
# Calculating the MLE of the parameters of the mixture of linear regressions.
mle.est <- linRegMixEM(c(0.4,0.3,0.3),c(0.1,-0.1,0.2),c(1,-1,1),c(1,0.5,1.1),q4.data$x,q4.data$Y,1e-06)

#pi MLEs
round(mle.est[[1]],3)
# (0.450, 0.255, 0.295)

#alpha MLEs
round(mle.est[[2]],3)
# (0.838,  7.458, -5.308)

#beta MLEs
round(mle.est[[3]],3)
# (0.258, -1.755,  1.223)

#sd MLEs
round(mle.est[[4]],3)
# (0.787, 0.935, 1.450)


############################################################## Question 5 ########################################################

### Part a ###

# Function performing bootstrap
# Note: The sampling does not assume need to preserve the number sampled from each group (eg bootstrap samples can have different number 
#of observations in each group from the original sample)

bootFStat <- function(group,y,w,bootCount){
  #object to store B bootstrap estimates of f statistic
  Fstat.boot.est <- NULL
  #grouping values into dataset 
  data <- data.frame("group"=group,"Obs"=y,"weight"=w)
  #Adding id column so can sample by id to retain all info of row (obs and weight)
  data$id <- seq(1,dim(data)[1])
  
  for (b in 1:bootCount){
    #object to store value of y tilde * N 
    y.tilde.N <- 0
    
    #sampling dataset to create bootstrap dataset
    sample.id <- sample(data$id, size = length(y), replace = TRUE)
    
    #Variables to store values of ith bootstrap sample observation, weight and group
    sample.obs <- sample.weight <- sample.group <- NULL
    
    #extracting weight, group and y value corresponding to id sampled
    for (i in 1:length(y)){
      sample.obs[i] <- data$Obs[data$id == sample.id[i]]
      sample.weight[i] <- data$weight[data$id == sample.id[i]]
      sample.group[i] <- data$group[data$id == sample.id[i]]
    }
    #creating dataset of bootstrap sample
    sample.dataset <- data.frame("group"=sample.group,"Obs"=sample.obs,"weight"=sample.weight)
    
    #computing statistics to calculate f-stat (for loop to calculate statistics seperately for each group)
    for (group_val in unique(sample.dataset$group)){
      group.dataset <- data.frame("Obs"=sample.dataset$Obs[sample.dataset==group_val],
                                  "weight"=sample.dataset$weight[sample.dataset==group_val])
      
      #calculating number of obs for current group
      assign(paste0("nobs.",group_val),dim(group.dataset)[1])
      
      #Calculating y tilde_{i} for current group
      y.tilde.group <- sum(group.dataset$Obs*group.dataset$weight)/dim(group.dataset)[1]
      assign(paste0("y.tilde.",group_val),y.tilde.group)
      
      #updating y tilde using current group
      y.tilde.N <- y.tilde.N + sum(group.dataset$Obs*group.dataset$weight)
      
      #Calculating part of denominator of f-statistic corresponding to current group
      f.denom.group.part <- sum((group.dataset$Obs*group.dataset$weight-y.tilde.group)^2)
      assign(paste0("f.denom.",group_val),f.denom.group.part)
      
    }
    #calculating y tilde
    y.tilde <- y.tilde.N/length(y)
    
    #calculating summation parts of numerator and denominator of f statistic
    fstat.num <- 0
    fstat.denom <- 0
    for (group_val in unique(data$group)){
      fstat.num <- fstat.num+get(paste0("nobs.",group_val))*(get(paste0("y.tilde.",group_val))-y.tilde)^2
      fstat.denom <- fstat.denom + get(paste0("f.denom.",group_val))
    }
    #calculating F stat
    fstat <- (fstat.num/(length(unique(group))-1))/(fstat.denom/(length(y)-length(unique(group))))
    Fstat.boot.est[b] <- fstat
    
  }
  #Calculating standard error of bootstrap f statistic
  bootstr.mu <- sum(Fstat.boot.est)/length(Fstat.boot.est)
  bootstr.se <- sqrt(sum((Fstat.boot.est-bootstr.mu )^2)/(length(Fstat.boot.est-1)))
  
  return(bootstr.se)
}

### Part b ###

eco.df <- read.table("q5EcoStudy.txt",header = T)
set.seed(2022)

#calculating bootstrap estimates of standard error for dataset using 1000 bootstrap replicates
round(bootFStat(eco.df$habitat,eco.df$density,eco.df$weight,1000),3) 
# Calculated standard error of f-statistic with degrees of freedom 2 and 297 is 4.131 (3 d.p.)

